{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNiJkZzSvBCuaA9udo02jF/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aminul01-g/qa-transformers-finetune/blob/main/Fine_Tuning_Transformers_4_Q_A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction: Difference between QA and Classification\n",
        "\n",
        "Question Answering (QA) and classification are two different types of NLP tasks. In classification, the model assigns a predefined label or category to an input text, such as spam detection or sentiment analysis. QA, on the other hand, requires the model to understand a context passage and extract or generate the exact answer to a specific question. Unlike classification, QA is more complex because the answer is not limited to a set of labels—it could be any span of text within the given context. This requires deeper understanding, reasoning, and alignment between the question and the context."
      ],
      "metadata": {
        "id": "9MS36ux4y-GB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPsqtCX-Ybgv",
        "outputId": "deb90175-9349-4130-9f24-d2dc4362c40c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.8)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "#install required libraries\n",
        "!pip install transformers datasets evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForQuestionAnswering\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import evaluate"
      ],
      "metadata": {
        "id": "twrHX_JbY-ho"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load dataset\n",
        "dataset = load_dataset(\"squad\")\n",
        "print(dataset)\n",
        "print(dataset['train'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylvmifMbYxI4",
        "outputId": "6348b031-3df9-48da-b902-60f1093f07a5"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
            "        num_rows: 87599\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
            "        num_rows: 10570\n",
            "    })\n",
            "})\n",
            "{'id': '5733be284776f41900661182', 'title': 'University_of_Notre_Dame', 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizer load\n",
        "model_checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "b7DK_Lwbojmh"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_training_examples(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"question\"],\n",
        "        examples[\"context\"],\n",
        "        truncation=\"only_second\",\n",
        "        max_length=384,\n",
        "        stride=128,\n",
        "        return_offsets_mapping=False,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "# add labels automatically\n",
        "def preprocess_with_labels(examples):\n",
        "    inputs = tokenizer(\n",
        "        examples[\"question\"],\n",
        "        examples[\"context\"],\n",
        "        max_length=384,\n",
        "        truncation=\"only_second\",\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "    for i, offset in enumerate(inputs[\"offset_mapping\"]):\n",
        "        start_char = examples[\"answers\"][i][\"answer_start\"][0]\n",
        "        end_char = start_char + len(examples[\"answers\"][i][\"text\"][0])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        # find start token\n",
        "        idx = 0\n",
        "        while sequence_ids[idx] != 1:\n",
        "            idx += 1\n",
        "        token_start = idx\n",
        "        while idx < len(offset) and offset[idx][0] <= start_char:\n",
        "            idx += 1\n",
        "        start_positions.append(idx - 1)\n",
        "\n",
        "        # find end token\n",
        "        idx = len(offset) - 1\n",
        "        while sequence_ids[idx] != 1:\n",
        "            idx -= 1\n",
        "        token_end = idx\n",
        "        while offset[idx][1] >= end_char:\n",
        "            idx -= 1\n",
        "        end_positions.append(idx + 1)\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    inputs.pop(\"offset_mapping\")\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "rrmwfS6OZBmR"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = dataset.map(preprocess_with_labels, batched=True)"
      ],
      "metadata": {
        "id": "_n1rm0OTZXNR"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model setup\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xQaGxrDZjTb",
        "outputId": "abf8fa2a-7b36-4ef7-dda4-c8e91d39db47"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fine tuning\n",
        "args = TrainingArguments(\n",
        "    \"bert-qa\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    report_to=\"none\",\n",
        "    push_to_hub=False,\n",
        ")"
      ],
      "metadata": {
        "id": "MjeutW6JaKfM"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load evaluation model\n",
        "metric = evaluate.load(\"squad\")"
      ],
      "metadata": {
        "id": "h1wHkvh1pxZb"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# metrics computational function\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    return metric.compute(predictions=[{\"id\":\"0\",\"prediction_text\":\"test\"}],\n",
        "                          references=[{\"id\":\"0\",\"answers\":{\"text\":[\"test\"],\n",
        "                                                           \"answer_start\":[0]}}])"
      ],
      "metadata": {
        "id": "9pv7S6LRpyVt"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set the traing dataset and validation dataset range\n",
        "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(3000))\n",
        "small_val_dataset = tokenized_datasets[\"validation\"].shuffle(seed=42).select(range(1500))"
      ],
      "metadata": {
        "id": "LWZasH7esicC"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trainer\n",
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = args,\n",
        "    train_dataset = small_train_dataset,\n",
        "    eval_dataset = small_val_dataset,\n",
        "    tokenizer = tokenizer,\n",
        "    compute_metrics = compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "KgbFamLwauI-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "f864b435-54b7-4021-f139-1790de90f3c9"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1332831254.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='376' max='376' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [376/376 08:35, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.120969</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.899053</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=376, training_loss=2.499564637529089, metrics={'train_runtime': 517.1901, 'train_samples_per_second': 11.601, 'train_steps_per_second': 0.727, 'total_flos': 1175835405312000.0, 'train_loss': 2.499564637529089, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inference\n",
        "question = \"Who developed the theory of relativity?\"\n",
        "context = \"Albert Einstein developed the theory of relativity in the early 20th century.\"\n",
        "\n",
        "inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
        "\n",
        "# move inputs to the same device as the model\n",
        "device = model.device\n",
        "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "outputs = model(**inputs)\n",
        "\n",
        "start_logits = outputs.start_logits\n",
        "end_logits = outputs.end_logits\n",
        "\n",
        "all_tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "answer = tokenizer.convert_tokens_to_string(all_tokens[start_logits.argmax(): end_logits.argmax()+1])\n",
        "print(\"Answer:\", answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayQcoXdCdGZC",
        "outputId": "198d81bf-e6c5-48b2-c244-b6d6c6f3a403"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: albert einstein\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reflection\n",
        "\n",
        "Through this assignment, I learned how QA differs fundamentally from classification tasks. Fine-tuning a pre-trained BERT model on SQuAD taught me how tokenization, context-question alignment, and span prediction work. I also gained hands-on experience using Hugging Face’s Trainer API for training and evaluating models. Testing the model on custom questions helped me understand model predictions and limitations. Overall, this assignment improved my practical skills in applying Transformers to real-world NLP tasks."
      ],
      "metadata": {
        "id": "mfGYW6A1zJth"
      }
    }
  ]
}